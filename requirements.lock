# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false
#   generate-hashes: false
#   universal: false

-e file:.
annotated-types==0.7.0
    # via pydantic
anyio==4.8.0
    # via httpx
cachetools==5.5.0
    # via papermill
certifi==2024.12.14
    # via httpcore
    # via httpx
    # via requests
charset-normalizer==3.4.1
    # via requests
extractous==0.3.0
    # via papermill
fancy-dataclass==0.8.1
    # via papermill
filelock==3.16.1
    # via huggingface-hub
    # via torch
    # via transformers
    # via triton
flpc==0.2.5
    # via papermill
fsspec==2024.12.0
    # via huggingface-hub
    # via torch
greenlet==3.1.1
    # via sqlalchemy
grpcio==1.69.0
    # via grpcio-tools
    # via qdrant-client
grpcio-tools==1.69.0
    # via qdrant-client
h11==0.14.0
    # via httpcore
h2==4.1.0
    # via httpx
hpack==4.0.0
    # via h2
httpcore==1.0.7
    # via httpx
httpx==0.28.1
    # via qdrant-client
huggingface-hub==0.27.0
    # via sentence-transformers
    # via tokenizers
    # via transformers
hyperframe==6.0.1
    # via h2
idna==3.10
    # via anyio
    # via httpx
    # via requests
jinja2==3.1.5
    # via torch
joblib==1.4.2
    # via scikit-learn
markupsafe==3.0.2
    # via jinja2
mpmath==1.3.0
    # via sympy
networkx==3.4.2
    # via torch
numpy==2.2.1
    # via qdrant-client
    # via scikit-learn
    # via scipy
    # via transformers
nvidia-cublas-cu12==12.4.5.8
    # via nvidia-cudnn-cu12
    # via nvidia-cusolver-cu12
    # via torch
nvidia-cuda-cupti-cu12==12.4.127
    # via torch
nvidia-cuda-nvrtc-cu12==12.4.127
    # via torch
nvidia-cuda-runtime-cu12==12.4.127
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.2.1.3
    # via torch
nvidia-curand-cu12==10.3.5.147
    # via torch
nvidia-cusolver-cu12==11.6.1.9
    # via torch
nvidia-cusparse-cu12==12.3.1.170
    # via nvidia-cusolver-cu12
    # via torch
###nvidia-nccl-cu12==2.21.5 # ignoring the requirement for now since it's only available on Linux
    # via torch
nvidia-nvjitlink-cu12==12.4.127
    # via nvidia-cusolver-cu12
    # via nvidia-cusparse-cu12
    # via torch
nvidia-nvtx-cu12==12.4.127
    # via torch
packaging==24.2
    # via huggingface-hub
    # via transformers
pillow==11.1.0
    # via sentence-transformers
portalocker==2.10.1
    # via qdrant-client
protobuf==5.29.2
    # via grpcio-tools
pydantic==2.10.4
    # via qdrant-client
pydantic-core==2.27.2
    # via pydantic
pymupdf==1.25.1
    # via papermill
pyyaml==6.0.2
    # via huggingface-hub
    # via transformers
qdrant-client==1.12.2
    # via papermill
regex==2024.11.6
    # via transformers
requests==2.32.3
    # via huggingface-hub
    # via transformers
safetensors==0.5.0
    # via transformers
scikit-learn==1.6.0
    # via sentence-transformers
scipy==1.15.0
    # via scikit-learn
    # via sentence-transformers
sentence-transformers==3.3.1
    # via papermill
setuptools==75.7.0
    # via grpcio-tools
    # via torch
sniffio==1.3.1
    # via anyio
sqlalchemy==2.0.37
    # via fancy-dataclass
sympy==1.13.1
    # via torch
threadpoolctl==3.5.0
    # via scikit-learn
tokenizers==0.21.0
    # via transformers
tomlkit==0.13.2
    # via fancy-dataclass
torch==2.5.1
    # via sentence-transformers
tqdm==4.67.1
    # via huggingface-hub
    # via sentence-transformers
    # via transformers
transformers==4.47.1
    # via sentence-transformers
###triton==3.1.0 # ignoring the requirement for now since it's only available on Linux
    # via torch
typing-extensions==4.12.2
    # via anyio
    # via fancy-dataclass
    # via huggingface-hub
    # via pydantic
    # via pydantic-core
    # via sqlalchemy
    # via torch
urllib3==2.3.0
    # via qdrant-client
    # via requests
xmltodict==0.14.2
    # via papermill
